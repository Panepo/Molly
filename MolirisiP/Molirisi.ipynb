{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Application Config\n",
    "EnableColorStream = 0\n",
    "ColorStreamResWidth = 1920\n",
    "ColorStreamResHeight = 1080\n",
    "ColorStreamFPS = 30\n",
    "\n",
    "EnableInfraredStream = 1\n",
    "InfraredStreamResWidth = 1280\n",
    "InfraredStreamResHeight = 720\n",
    "InfraredStreamFPS = 30\n",
    "\n",
    "EnableDepthStream = 1\n",
    "DepthStreamResWidth = 1280\n",
    "DepthStreamResHeight = 720\n",
    "DepthStreamFPS = 30\n",
    "\n",
    "maxDistance = 1000      \n",
    "capture = 0\n",
    "point = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth scale:0.0010000000474974513\n"
     ]
    }
   ],
   "source": [
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "if EnableColorStream:\n",
    "    config.enable_stream(\n",
    "        rs.stream.color, ColorStreamResWidth, ColorStreamResHeight, rs.format.bgr8, ColorStreamFPS)\n",
    "\n",
    "if EnableInfraredStream:\n",
    "    config.enable_stream(\n",
    "        rs.stream.infrared, InfraredStreamResWidth, InfraredStreamResHeight, rs.format.bgr8, InfraredStreamFPS)\n",
    "    \n",
    "if EnableDepthStream:\n",
    "    config.enable_stream(\n",
    "        rs.stream.depth, DepthStreamResWidth, DepthStreamResHeight, rs.format.z16, DepthStreamFPS)\n",
    "\n",
    "# Start streaming\n",
    "cfg = pipeline.start(config)\n",
    "\n",
    "# Advanced settings\n",
    "dev = cfg.get_device()\n",
    "depth_sensor = dev.first_depth_sensor()\n",
    "depth_sensor.set_option(rs.option.visual_preset, 4)\n",
    "depth_sensor.set_option(rs.option.enable_auto_exposure, 1)\n",
    "\n",
    "# Get depth scale\n",
    "scale = depth_sensor.get_depth_scale()\n",
    "print(\"depth scale:\" + str(scale))\n",
    "\n",
    "# PointCloud settings\n",
    "pc = rs.pointcloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'pyrealsense2.BufData' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d46bfbedc226>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mvertices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'pyrealsense2.BufData' object does not support indexing"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Wait for a coherent pair of frames: depth and color\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    \n",
    "    if EnableColorStream:\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not color_frame:\n",
    "            continue\n",
    "            \n",
    "    if EnableInfraredStream:\n",
    "        infrared_frame = frames.first(rs.stream.infrared)\n",
    "        if not infrared_frame:\n",
    "            continue\n",
    "    \n",
    "    if EnableDepthStream:\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        if not depth_frame:\n",
    "            continue\n",
    "    \n",
    "    # Convert images to numpy arrays\n",
    "    if EnableColorStream:\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "    \n",
    "    if EnableInfraredStream:\n",
    "        infrared_image = np.asanyarray(infrared_frame.get_data())\n",
    "    \n",
    "    if EnableDepthStream:\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    \n",
    "    # colorize depth image\n",
    "    minNum, maxNum, minLoc, maxLoc = cv2.minMaxLoc(depth_image)\n",
    "\n",
    "    if maxNum > maxDistance:\n",
    "        maxNum = maxDistance\n",
    "    \n",
    "    scaleAlpha = 255 / maxNum\n",
    "    depth_image = cv2.convertScaleAbs(depth_image, None, scaleAlpha, 0)\n",
    "    depth_colormap = cv2.applyColorMap(depth_image, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Show images\n",
    "    if EnableColorStream:\n",
    "        cv2.imshow('Color image', color_image)\n",
    "        \n",
    "    if EnableInfraredStream:\n",
    "        cv2.imshow('Infrared image', infrared_image)\n",
    "    \n",
    "    if EnableDepthStream:\n",
    "        cv2.imshow('Depth image', depth_colormap)\n",
    "    \n",
    "    # Screen capture\n",
    "    if capture:\n",
    "        if EnableColorStream:\n",
    "            fileName = \"../imageCapture/color_\" + time.strftime(\"%Y-%m-%d_%H%M%S-\", time.localtime()) + '.png'\n",
    "            cv2.imwrite(fileName, color_image, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n",
    "        \n",
    "        if EnableInfraredStream:\n",
    "            fileName = \"../imageCapture/infrared_\" + time.strftime(\"%Y-%m-%d_%H%M%S-\", time.localtime()) + '.png'\n",
    "            cv2.imwrite(fileName, infrared_image, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n",
    "        \n",
    "        if EnableDepthStream:\n",
    "            fileName = \"../imageCapture/depth_\" + time.strftime(\"%Y-%m-%d_%H%M%S-\", time.localtime()) + '.png'\n",
    "            cv2.imwrite(fileName, depth_colormap, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n",
    "        \n",
    "        capture = 0\n",
    "        \n",
    "    # Read device temperature\n",
    "    '''\n",
    "    temp = depth_sensor.get_option(rs.option.projector_temperature)\n",
    "    print(\"proj: \" + str(temp))\n",
    "    temp = depth_sensor.get_option(rs.option.asic_temperature)\n",
    "    print(\"asic: \" + str(temp))\n",
    "    '''\n",
    "    \n",
    "    # Generate point cloud\n",
    "    if point is 1:\n",
    "        point = 0\n",
    "        points = pc.calculate(depth_frame)\n",
    "        \n",
    "        if EnableColorStream:\n",
    "            pc.map_to(color_frame)\n",
    "            \n",
    "        if EnableColorStream:\n",
    "            pc.map_to(infrared_frame)\n",
    "            \n",
    "        vertices = points.get_vertices()\n",
    "        tex_coords = points.get_texture_coordinates()\n",
    "        \n",
    "        for i in range(0, points.size()):\n",
    "            if vertices[i].z:\n",
    "                print(vertices[i].x)\n",
    "                print(vertices[i].y)\n",
    "                print(vertices[i].z)\n",
    "                break\n",
    "        \n",
    "\n",
    "    # Keyboard command\n",
    "    getKey = cv2.waitKey(10) & 0xFF\n",
    "    if getKey is ord('c') or getKey is ord('C'):\n",
    "        capture = 1\n",
    "    elif getKey is ord('q') or getKey is ord('Q'):\n",
    "        break\n",
    "    elif getKey is ord('p') or getKey is ord('P'):\n",
    "        point = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stop streaming\n",
    "cv2.destroyAllWindows()\n",
    "pipeline.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
